{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw4.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1HjKIub8R75Hr_RwEhTm7GlGAXoHxw-Ym","authorship_tag":"ABX9TyNwbrJ/vCWh6BojFbnKA33m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3FXEAatNqUR4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"status":"ok","timestamp":1595676710394,"user_tz":-480,"elapsed":9429,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}},"outputId":"18591d59-37ec-4f53-f200-d3dda3dcd49b"},"source":["!gdown --id '1lz0Wtwxsh5YCPdqQ3E3l_nbfJT1N13V8' --output data.zip\n","!unzip data.zip"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1lz0Wtwxsh5YCPdqQ3E3l_nbfJT1N13V8\n","To: /content/data.zip\n","45.1MB [00:00, 67.8MB/s]\n","Archive:  data.zip\n","  inflating: training_label.txt      \n","  inflating: testing_data.txt        \n","  inflating: training_nolabel.txt    \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LQQ8n_xyUa67","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595676800054,"user_tz":-480,"elapsed":1616,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}}},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"BNaL5GL4r0v6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595676805684,"user_tz":-480,"elapsed":4790,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}}},"source":["import torch\n","import numpy as np\n","import pandas as pd\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jmeGdI1tRsSA","colab_type":"text"},"source":["Three datasets:\n","- training_label.txt:\n","    - e.g., 1 +++$+++ are wtf ... awww thanks !\n","- training_nolabel.txt\n","    - e.g., hates being this burnt !! ouch\n","- testing_data.txt\n","    ```\n","    id,text\n","    0,my dog ate our dinner . no , seriously ... he ate it .\n","    1,omg last day sooon n of primary noooooo x im gona be swimming out of school wif the amount of tears am gona cry\n","    ```\n"]},{"cell_type":"markdown","metadata":{"id":"z8EVhLu-7u_N","colab_type":"text"},"source":["## Load the data"]},{"cell_type":"code","metadata":{"id":"6njk06hmSSH-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595676805686,"user_tz":-480,"elapsed":1166,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}}},"source":["def load_training_data(path, labeled):\n","    if labeled:\n","        with open(path, 'r') as f:\n","            lines = f.readlines()\n","            lines = [line.strip('\\n').split(' ') for line in lines]\n","        x = [line[2:] for line in lines]\n","        y = [int(line[0]) for line in lines]\n","        return x, y    \n","    else:\n","        with open(path, 'r') as f:\n","            lines = f.readlines()\n","        x = [line.strip('\\n').split(' ') for line in lines]\n","        return x\n","def load_testing_data(path):\n","    with open(path, 'r') as f:\n","        lines = f.readlines()\n","    x = [\"\".join(line.strip('\\n').split(',')[1:]).strip() for line in lines[1:]]\n","    x = [sen.split(' ') for sen in x]\n","    return x"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QLrhUaLutR9e","colab_type":"text"},"source":["## Train Word2Vec"]},{"cell_type":"code","metadata":{"id":"CuMRXwoIMvsp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1595676919575,"user_tz":-480,"elapsed":7257,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}},"outputId":"441bb5ea-46f5-447d-87da-62fd866b522a"},"source":["print(\"loading training data ... \", end='')\n","train_x, train_y = load_training_data('training_label.txt', True)\n","train_x_no_label = load_training_data('training_nolabel.txt', False)\n","print(\"done.\")\n","\n","print(\"loading testing data ... \", end='')\n","test_x = load_testing_data('testing_data.txt')\n","print(\"done.\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["loading training data ... done.\n","loading testing data ... done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cnzyNeuSTNJI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1595678091227,"user_tz":-480,"elapsed":1160155,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}},"outputId":"d9cc6fcc-9232-4371-a2f2-0bcf39341e81"},"source":["from gensim.models import word2vec\n","\n","print('training word2vec model ... ', end='')\n","# model = word2vec.Word2Vec(train_x + test_x, size=250, window=5, min_count=5, workers=12, iter=10, sg=1)\n","model = word2vec.Word2Vec(train_x + test_x + train_x_no_label, size=250, window=5, min_count=5, workers=12, iter=10, sg=1)\n","print('done.')\n","\n","print('saving word2vec model ... ', end='')\n","model.save('model/word2vec_all.model')\n","print('done.')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["training word2vec model ... done.\n","saving word2vec model ... done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gdOLke6tpBOL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"status":"ok","timestamp":1595678091228,"user_tz":-480,"elapsed":1147551,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}},"outputId":"48acf077-a2d2-4b4a-fc8e-100a9466500a"},"source":["from gensim.models import word2vec\n","# Test word2vec\n","embedding = word2vec.Word2Vec.load('model/word2vec_all.model')\n","embedding_dim = embedding.vector_size\n","model.wv.similar_by_word('haha', topn=20) # some test"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('hahaha', 0.8560881018638611),\n"," ('lol', 0.8301147222518921),\n"," ('hehe', 0.759688675403595),\n"," ('hahah', 0.7439364194869995),\n"," ('ahaha', 0.7049542665481567),\n"," ('lmao', 0.6756629943847656),\n"," ('hahahaha', 0.6402173638343811),\n"," ('hah', 0.6286949515342712),\n"," ('aha', 0.617099940776825),\n"," ('hahahah', 0.5905086994171143),\n"," ('yeahp', 0.5903643369674683),\n"," ('hehehe', 0.5889112949371338),\n"," ('xd', 0.5817236304283142),\n"," ('hahahahha', 0.5782143473625183),\n"," ('lmfao', 0.5755268931388855),\n"," ('hahaa', 0.5672986507415771),\n"," ('hahha', 0.5605295896530151),\n"," ('hhahahaha', 0.5558002591133118),\n"," ('nawh', 0.5549719333648682),\n"," ('ahah', 0.5528687238693237)]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"W3IYIfHkpE-y","colab_type":"text"},"source":["## Data Preprocess"]},{"cell_type":"code","metadata":{"id":"ORYY0M73vciP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595678091228,"user_tz":-480,"elapsed":1144876,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}}},"source":["class Preprocess():\n","    def __init__(self, sentences, sen_len, w2v_path='model/word2vec_all.model'):\n","        self.w2v_path = w2v_path\n","        self.sentences = sentences\n","        self.sen_len = sen_len\n","        self.idx2word = []\n","        self.word2idx = {}\n","        self.embedding_matrix = []\n","    def get_w2v_model(self):\n","        self.embedding = word2vec.Word2Vec.load(self.w2v_path)\n","        self.embedding_dim = self.embedding.vector_size\n","    def add_embedding(self, word):\n","        vector = torch.empty(1, self.embedding_dim)\n","        torch.nn.init.uniform_(vector)\n","        self.word2idx[word] = len(self.word2idx)\n","        self.idx2word.append(word)\n","        self.embedding_matrix = torch.cat([self.embedding_matrix, vector], 0)\n","    def make_embedding(self):\n","        self.get_w2v_model()\n","        for i, word in enumerate(self.embedding.wv.vocab):\n","            self.word2idx[word] = len(self.word2idx)\n","            self.idx2word.append(word)\n","            self.embedding_matrix.append(self.embedding[word])\n","        self.embedding_matrix = torch.tensor(self.embedding_matrix)\n","        self.add_embedding('<PAD>')\n","        self.add_embedding('<UNK>')\n","        return self.embedding_matrix\n","    def pad_sequence(self, sentence):\n","        if len(sentence) > self.sen_len:\n","            sentence = sentence[:self.sen_len]\n","        else:\n","            for _ in range(self.sen_len - len(sentence)):\n","                sentence.append(self.word2idx['<PAD>'])\n","        return sentence\n","    def sentence_word2idx(self):\n","        sentence_list = []\n","        for i, sen in enumerate(self.sentences):\n","            sentence_idx = []\n","            for word in sen:\n","                if (word in self.word2idx.keys()):\n","                    sentence_idx.append(self.word2idx[word])\n","                else:\n","                    sentence_idx.append(self.word2idx['<UNK>'])\n","            sentence_idx = self.pad_sequence(sentence_idx)\n","            sentence_list.append(sentence_idx)\n","        return torch.LongTensor(sentence_list)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CPsOPJ9nOdfn","colab_type":"text"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"79aaQxiuOdK_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595678091229,"user_tz":-480,"elapsed":1144546,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}}},"source":["from torch.utils import data\n","\n","class TwitterDataset(data.Dataset):\n","    def __init__(self, X, y):\n","        self.data = X\n","        self.label = y\n","    def __getitem__(self, idx):\n","        if self.label is None:\n","            return self.data[idx]\n","        else:\n","            return self.data[idx], self.label[idx]\n","    def __len__(self):\n","        return len(self.data)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C5v98-9iUkh0","colab_type":"text"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"00N3NHa6UkK_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595678091230,"user_tz":-480,"elapsed":1144275,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}}},"source":["import torch.nn as nn\n","\n","class LSTM_Net(nn.Module):\n","    def __init__(self, embedding, embedding_dim, hidden_dim, num_layers, dropout=0.5, fix_embedding=True):\n","        super(LSTM_Net, self).__init__()\n","        self.embedding = torch.nn.Embedding(embedding.size(0), embedding.size(1))\n","        self.embedding.weight = torch.nn.Parameter(embedding)\n","        self.embedding.weight.requires_grad = not fix_embedding\n","        self.embedding_dim = embedding.size(1)\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.dropout = dropout\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n","        self.classifier = nn.Sequential(nn.Dropout(dropout), nn.Linear(hidden_dim, 1), nn.Sigmoid())\n","    \n","    def forward(self, inputs):\n","        inputs = self.embedding(inputs)\n","        x, _ = self.lstm(inputs, None)\n","        x = x[:, -1, :]\n","        x = self.classifier(x)\n","        return x"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aBx85GirfC1R","colab_type":"text"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"JSIPBYaLiC_G","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595678091230,"user_tz":-480,"elapsed":1143987,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}}},"source":["def evaluation(outputs, labels):\n","    outputs[outputs >= 0.5] = 1\n","    outputs[outputs < 0.5] = 0\n","    correct = torch.sum(torch.eq(outputs, labels)).item()\n","    return correct"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"2voiaVG1fCZb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595678091231,"user_tz":-480,"elapsed":1143841,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}}},"source":["def training(batch_size, n_epoch, lr, model_dir, train_loader, val_loader, model, device):\n","    loss_func = nn.BCELoss() # Binary Cross Entropy Loss\n","    train_batch = len(train_loader)\n","    val_batch = len(val_loader)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    best_acc = 0\n","    print('Start training ...')\n","    for epoch in range(n_epoch):\n","        total_loss, total_acc = 0, 0\n","        model.train()\n","        for i, (inputs, labels) in enumerate(train_loader):\n","            inputs = inputs.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.float)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            outputs = outputs.squeeze()\n","            loss = loss_func(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            correct = evaluation(outputs, labels)\n","            total_acc += correct / batch_size\n","            total_loss += loss.item()\n","            print('[ Epoch{}: {}/{} ] loss:{:.3f} acc:{:.3f} '.format(\n","             \tepoch+1, i+1, train_batch, loss.item(), correct*100/batch_size))\n","        print('\\nTrain | Loss:{:.5f} Acc: {:.3f}'.format(total_loss/train_batch, total_acc/train_batch*100))\n","\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_acc = 0, 0\n","            for i, (inputs, labels) in enumerate(val_loader):\n","                inputs = inputs.to(device, dtype=torch.long)\n","                labels = labels.to(device, dtype=torch.float)\n","                outputs = model(inputs)\n","                outputs = outputs.squeeze()\n","                loss = loss_func(outputs, labels)\n","                correct = evaluation(outputs, labels)\n","                total_acc += correct / batch_size\n","                total_loss += loss.item()\n","            print('valid | Loss:{:.5f} Acc: {:.3f}'.format(total_loss/val_batch, total_acc/val_batch*100))\n","            if total_acc > best_acc:\n","                best_acc = total_acc\n","                print('saving model with acc {:.3f} ... '.format(total_acc/val_batch*100), end='')\n","                torch.save(model, \"{}/best_model.model\".format(model_dir))\n","                print('done.')\n","        print('--------------------------------------')"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yYMzeOQb3rpT","colab_type":"text"},"source":["## Testing"]},{"cell_type":"code","metadata":{"id":"-oLgHZ3BdXXK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595679399792,"user_tz":-480,"elapsed":1093,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}}},"source":["def testing(batch_size, test_loader, model, device):\n","    model.eval()\n","    ret_output = []\n","    with torch.no_grad():\n","        for i, inputs in enumerate(test_loader):\n","            inputs = inputs.to(device, dtype=torch.long)\n","            outputs = model(inputs)\n","            outputs = outputs.squeeze()\n","            outputs[outputs >= 0.5] = 1\n","            outputs[outputs < 0.5] = 0\n","            ret_output += outputs.int().tolist()\n","    return ret_output"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oBqejB1jLu-N","colab_type":"text"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"h77iJY-ZCUKD","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_dir = 'model'\n","\n","# super parameters\n","batch_size = 128\n","n_epoch = 10\n","lr = 0.001\n","\n","# preprocess\n","preprocess = Preprocess(train_x, sen_len=20, w2v_path='model/word2vec_all.model')\n","embedding = preprocess.make_embedding()\n","train_x_idx = preprocess.sentence_word2idx()\n","train_y_tensor = torch.LongTensor(train_y)\n","\n","# select validation data from training data\n","val_size = int(0.1 * len(train_x_idx))\n","X_train, X_val = train_x_idx[val_size:], train_x_idx[:val_size]\n","y_train, y_val = train_y_tensor[val_size:], train_y_tensor[:val_size]\n","\n","train_dataset = TwitterDataset(X_train, y_train)\n","val_dataset = TwitterDataset(X_val, y_val)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           num_workers=8)\n","val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n","                                           batch_size=batch_size,\n","                                           shuffle=False,\n","                                           num_workers=8)\n","\n","model = LSTM_Net(embedding, embedding_dim=250, hidden_dim=150, num_layers=1, dropout=0.5)\n","model.to(device)\n","\n","training(batch_size, n_epoch, lr, model_dir, train_loader, val_loader, model, device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JbdzQxqe13sn","colab_type":"text"},"source":["## Predict"]},{"cell_type":"code","metadata":{"id":"zA5fME8D27OJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1595679410213,"user_tz":-480,"elapsed":7972,"user":{"displayName":"Ada Yuan","photoUrl":"","userId":"03330682283325748846"}},"outputId":"a954bb3c-636a-4b25-8370-0cb721e2a893"},"source":["print('Predicting for test data ...')\n","\n","# preprocess\n","preprocess = Preprocess(test_x, sen_len=20, w2v_path='model/word2vec_all.model')\n","embedding = preprocess.make_embedding()\n","test_x_idx = preprocess.sentence_word2idx()\n","test_dataset = TwitterDataset(X=test_x_idx, y=None)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                           batch_size=batch_size,\n","                                           shuffle=False,\n","                                           num_workers=8)\n","\n","print('loading model ...', end='')\n","model = torch.load('model/best_model.model')\n","print('done.')\n","\n","outputs = testing(batch_size, test_loader, model, device)\n","\n","df = pd.DataFrame({\"id\":[str(i) for i in range(len(test_x))],\"label\":outputs})\n","print(\"saving csv ...\")\n","df.to_csv('predict.csv', index=False)\n","\n","print(\"Finish Predicting\")"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Predicting for test data ...\n","loading model ...done.\n","saving csv ...\n","Finish Predicting\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kuls-0IX6FWL","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}